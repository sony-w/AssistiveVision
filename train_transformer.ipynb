{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ipywidgets nltk tqdm #cython\n",
    "#%pip install git+https://github.com/facebookresearch/fvcore.git\n",
    "#python -m pip install detectron2 -f \\\n",
    "#  https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n",
    "#python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html \n",
    "# https://stackoverflow.com/questions/62081155/pytorch-indexerror-index-out-of-range-in-self-how-to-solve\n",
    "# https://www.programmersought.com/article/97387644893/\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#if not os.path.join(os.getcwd(), 'pycocotools') in sys.path:\n",
    "#    sys.path.append(os.path.join(os.getcwd(), 'pycocotools'))\n",
    "\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import gc\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "#from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "#from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.nn import NLLLoss\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from loader.dataset_coco import COCODataset\n",
    "from loader.images import ImageS3\n",
    "from loader.model import ModelS3\n",
    "from loader.vocab import construct_vocab\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "from commons.utils import embedding_matrix, tensor_to_word_fn\n",
    "from models.transformer import MemoryAugmentedEncoder, MeshedDecoder, Transformer, ScaledDotProductAttentionMemory\n",
    "\n",
    "from eval.metrics import bleu, cider, rouge, spice, meteor, bleu_score_fn\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(1111)\n",
    "np.random.seed(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n",
      "0.1\n",
      "10.1\n"
     ]
    }
   ],
   "source": [
    "import detectron2\n",
    "\n",
    "print(torch.__version__)\n",
    "print(detectron2.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config 'bua/configs/VG-Detection/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modifications for VG in ResNet Backbone (modeling/backbone/resnet.py):\n",
      "\tUsing pad 0 in stem max_pool instead of pad 1.\n",
      "\n",
      "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
      "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
      "\n",
      "Modifications for VG in RoI heads (modeling/roi_heads/roi_heads.py):\n",
      "\t1. Change the stride of conv1 and shortcut in Res5.Block1 from 2 to 1.\n",
      "\t2. Modifying all conv2 with (padding: 1 --> 2) and (dilation: 1 --> 2).\n",
      "\tFor more details, please check 'https://github.com/peteanderson80/bottom-up-attention/blob/master/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'.\n",
      "\n",
      "Modifications for VG in RoI heads (modeling/roi_heads/fast_rcnn.py))\n",
      "\tEmbedding: 1601 --> 256\tLinear: 2304 --> 512\tLinear: 512 --> 401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "#cfg.set_new_allowed(True)\n",
    "cfg.merge_from_file('bua/configs/VG-Detection/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml')\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 300\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.6\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.2\n",
    "# VG Weight\n",
    "\n",
    "# curl https://nlp.cs.unc.edu/models/faster_rcnn_from_caffe_attr_original.pkl --output bua/weights/faster_rcnn_from_caffe_attr_original.pkl\n",
    "cfg.MODEL.WEIGHTS = 'bua/weights/faster_rcnn_from_caffe_attr_original.pkl'  \n",
    "# 'https://nlp.cs.unc.edu/models/faster_rcnn_from_caffe_attr_original.pkl' \n",
    "# 'http://nlp.cs.unc.edu/models/faster_rcnn_from_caffe_attr.pkl'\n",
    "#if not torch.cuda.is_available():\n",
    "cfg.MODEL.DEVICE = device.type\n",
    "\n",
    "#cfg\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.39s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenizing caption... done!!\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenizing caption... done!!\n"
     ]
    }
   ],
   "source": [
    "train = COCODataset(dtype='train', ret_type='tensor', predictor=predictor, copy_img_to_mem=False, device=device, partial=100) #\n",
    "val = COCODataset(dtype='val', ret_type='tensor', predictor=predictor, copy_img_to_mem=False, device=device, partial=50) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = construct_vocab(train.df, val.df)\n",
    "train.vocabulary = vocabulary\n",
    "val.vocabulary = vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenizing caption... done!!\n"
     ]
    }
   ],
   "source": [
    "val_eval = COCODataset(dtype='val', ret_type='corpus', predictor=predictor, copy_img_to_mem=False, \n",
    "                       vocabulary=vocabulary, device=device, partial=50) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "no caption found... done!!\n"
     ]
    }
   ],
   "source": [
    "test = COCODataset(dtype='test', ret_type='corpus', predictor=predictor, copy_img_to_mem=False, \n",
    "                   vocabulary=vocabulary, device=device, partial=10) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'assistive-vision'\n",
    "MODEL = 'm2_transformer_multiheadatt'\n",
    "GLOVE_DIR = 'annotations/glove'\n",
    "\n",
    "MEMORY_SLOTS = 40\n",
    "NUM_HEAD = 8\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "BATCH_SIZE = 16 #10\n",
    "LOG_INTERVAL = 25 * (256 // BATCH_SIZE)\n",
    "LR = 1\n",
    "LR_WARMUP = 10000\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "LOCAL_PATH = 'bin/'\n",
    "KEY_PATH = 'bin/'\n",
    "CHEKCPOINTS_PATH = 'checkpoints/'\n",
    "CAPTIONS_PATH = 'captions/'\n",
    "VERSION = '1.0'\n",
    "\n",
    "MODEL_NAME = f'{MODEL}_b{BATCH_SIZE}_mha{NUM_HEAD}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_lr(s):\n",
    "    warm_up = LR_WARMUP\n",
    "    s += 1\n",
    "    return (model.d_model ** -.5) * min(s ** -.5, s * warm_up ** -1.5)\n",
    "\n",
    "def training(model, dataloader, optim, desc=''):\n",
    "    \n",
    "    # Training with cross-entropy\n",
    "    means = dict()\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "\n",
    "        running_loss = .0\n",
    "    \n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        t = tqdm(iter(dataloaders[phase]), desc=f'{desc} ::: {phase}')\n",
    "        \n",
    "        with torch.set_grad_enabled(phase == 'train'):\n",
    "            for batch_idx, batch in enumerate(t):\n",
    "                images, captions, lengths, fname, image_id = batch\n",
    "\n",
    "                out = model(images, captions)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optim.zero_grad()\n",
    "\n",
    "                captions_gt = captions[:, 1:].contiguous()\n",
    "                out = out[:, :-1].contiguous()\n",
    "                loss = loss_fn(out.view(-1, len(vocabulary)), captions_gt.view(-1))\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optim.step()\n",
    "                    scheduler.step()\n",
    "\n",
    "                this_loss = loss.item()\n",
    "                running_loss += this_loss\n",
    "\n",
    "                t.set_postfix({\n",
    "                        'loss': running_loss / (batch_idx + 1)\n",
    "                    }, refresh=True)\n",
    "\n",
    "                if (batch_idx + 1) % LOG_INTERVAL == 0 :\n",
    "                    print(f'{desc}_{phase} {batch_idx + 1}/{len(dataloader)} '\n",
    "                          f'{phase}_loss: {loss / (batch_idx + 1):.4f} ')\n",
    "\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                # release gpu memory\n",
    "                del images\n",
    "                del captions\n",
    "                gc.collect()\n",
    "                if device.type == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            means[phase] = running_loss / len(dataloaders[phase])\n",
    "\n",
    "    return means['train'], means['val']\n",
    "\n",
    "def evaluate(model, dataloader, bleu_score_fn, tensor_to_word_fn, desc=''):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    pred_byfname = dict()\n",
    "    caps_byfname = defaultdict(list)\n",
    "    scores = dict()\n",
    "    \n",
    "    running_bleu = [0.0] * 5\n",
    "    \n",
    "    t = tqdm(iter(data_loader), desc=f'{desc}')\n",
    "    for batch_idx, batch in enumerate(t):\n",
    "        images, captions, lengths, fname, image_id = batch\n",
    "        \n",
    "        out, _ = model.beam_search(images, 20, vocabulary.word2idx['<end>'], 5, out_size=1)\n",
    "        outputs = tensor_to_word_fn(out.cpu().numpy())\n",
    "        \n",
    "        for i in range(1, 5):\n",
    "            running_bleu[i] += bleu_score_fn(reference_corpus=captions, candidate_corpus=outputs, n=i)\n",
    "        t.set_postfix({\n",
    "            'bleu1': running_bleu[1] / (batch_idx + 1),\n",
    "            'bleu4': running_bleu[4] / (batch_idx + 1)\n",
    "        }, refresh=True)\n",
    "        \n",
    "        for f, o, c in zip(fname, outputs, captions):\n",
    "            if not f in pred_byfname:\n",
    "                pred_byfname[f] = [detokenize(o)]\n",
    "            caps_byfname[f].append(detokenize(c))\n",
    "        \n",
    "        # release gpu memory\n",
    "        del images\n",
    "        del captions\n",
    "        gc.collect()\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # mean running_bleu score\n",
    "    for i in range(1, 5):\n",
    "        running_bleu[i] /= len(data_loader)\n",
    "    scores['bleu'] = running_bleu\n",
    "\n",
    "    # calculate overall score\n",
    "    scores['coco_bleu'] = bleu(caps_byfname, pred_byfname, verbose=0)\n",
    "    scores['cider'] = cider(caps_byfname, pred_byfname)\n",
    "    scores['rouge'] = rouge(caps_byfname, pred_byfname)\n",
    "    #scores['spice'] = spice(caps_byfname, pred_byfname)\n",
    "    #scores['meteor'] = meteor(caps_byfname, pred_byfname)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def generate_captions(dataloader, model, desc=''):\n",
    "    rlist = []\n",
    "    \n",
    "    t = tqdm(iter(dataloader), desc=f'{desc}')\n",
    "    for batch_idx, batch in enumerate(t):\n",
    "        images, fname, image_id = batch\n",
    "        \n",
    "        out, _ = model.beam_search(images, 20, vocabulary.word2idx['<end>'], 5, out_size=1)\n",
    "        outputs = tensor_to_word_fn(out.cpu().numpy())\n",
    "\n",
    "        for out, img in zip(outputs, image_id):\n",
    "            result = dict(\n",
    "                image_id = int(img),\n",
    "                caption = detokenize(out)\n",
    "            )\n",
    "            rlist.append(result)\n",
    "        \n",
    "        # release gpu memory\n",
    "        del images\n",
    "        gc.collect()\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return rlist\n",
    "\n",
    "def detokenize(tokens):\n",
    "    return ''.join([' ' + i if not i.startswith(\"'\") and i not in string.punctuation else i for i in tokens]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sinusoid_encoding_table tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  8.2186e-01,  ...,  1.0000e+00,\n",
      "          1.0366e-04,  1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  9.3641e-01,  ...,  1.0000e+00,\n",
      "          2.0733e-04,  1.0000e+00],\n",
      "        ...,\n",
      "        [ 9.8663e-01, -1.6299e-01, -1.0289e-01,  ...,  9.9998e-01,\n",
      "          5.3905e-03,  9.9999e-01],\n",
      "        [ 3.9593e-01, -9.1828e-01,  7.5888e-01,  ...,  9.9998e-01,\n",
      "          5.4941e-03,  9.9998e-01],\n",
      "        [-5.5879e-01, -8.2931e-01,  9.6755e-01,  ...,  9.9998e-01,\n",
      "          5.5978e-03,  9.9998e-01]])\n",
      "sinusoid_encoding_table.shape torch.Size([55, 512])\n"
     ]
    }
   ],
   "source": [
    "# Model and dataloaders\n",
    "# reminder to save the vocabulary, encoder, and decoder\n",
    "encoder = MemoryAugmentedEncoder(3, 0, attention_module=ScaledDotProductAttentionMemory,\n",
    "                                 attention_module_kwargs={'m': MEMORY_SLOTS})\n",
    "decoder = MeshedDecoder(len(vocabulary), 54, 3, vocabulary.word2idx['<pad>']) # vocabulary.max_len\n",
    "model = Transformer(vocabulary.word2idx['<start>'], encoder, decoder).to(device)\n",
    "\n",
    "optim = Adam(model.parameters(), lr=LR, betas=(0.9, 0.98))\n",
    "scheduler = LambdaLR(optim, lambda_lr)\n",
    "loss_fn = NLLLoss(ignore_index=vocabulary.word2idx['<pad>'])\n",
    "\n",
    "corpus_bleu_score_fn = bleu_score_fn(4, 'corpus')\n",
    "tensor2word_fn = tensor_to_word_fn(idx2word=vocabulary.idx2word)\n",
    "\n",
    "model_bin = ModelS3()\n",
    "\n",
    "fname = f'{MODEL_NAME}_bin_v{VERSION}.pkl'\n",
    "model_bin.save_pkl(model, os.path.join(LOCAL_PATH, fname), os.path.join(KEY_PATH, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = dict(\n",
    "    train = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True, sampler=None, pin_memory=False),\n",
    "    val = DataLoader(val, batch_size=BATCH_SIZE, shuffle=True, sampler=None, pin_memory=False)\n",
    ")\n",
    "\n",
    "eval_collate_fn = lambda batch: (torch.stack([x[0] for x in batch]), [x[1] for x in batch], [x[2] for x in batch], \n",
    "                                 [x[3] for x in batch], [x[4] for x in batch])\n",
    "test_collate_fn = lambda batch: (torch.stack([x[0] for x in batch]), [x[1] for x in batch], [x[2] for x in batch])\n",
    "\n",
    "val_eval_loader = DataLoader(val_eval, batch_size=BATCH_SIZE, shuffle=False, sampler=None, pin_memory=False, collate_fn=eval_collate_fn)\n",
    "test_loader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False, sampler=None, pin_memory=False, collate_fn=test_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4dfbd501be4b798b9fcc70d83dbe8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 of 2 ::: train:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/py-bottom-up-attention/detectron2/modeling/roi_heads/fast_rcnn.py:101: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370116979/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  filter_inds = filter_mask.nonzero()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_queries tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]])\n",
      "mask_queries.shape torch.Size([16, 15, 1])\n",
      "_is_stateful False\n",
      "seq tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]])\n",
      "seq.shape torch.Size([16, 15])\n",
      "pos_emb tensor([[[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]],\n",
      "\n",
      "        [[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]],\n",
      "\n",
      "        [[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]],\n",
      "\n",
      "        [[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]],\n",
      "\n",
      "        [[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]]])\n",
      "mask_queries tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]])\n",
      "mask_queries.shape torch.Size([16, 15, 1])\n",
      "_is_stateful False\n",
      "seq tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]])\n",
      "seq.shape torch.Size([16, 15])\n",
      "pos_emb tensor([[[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]],\n",
      "\n",
      "        [[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]],\n",
      "\n",
      "        [[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]],\n",
      "\n",
      "        [[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]],\n",
      "\n",
      "        [[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]]])\n",
      "mask_queries tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]])\n",
      "mask_queries.shape torch.Size([16, 15, 1])\n",
      "_is_stateful False\n",
      "seq tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]])\n",
      "seq.shape torch.Size([16, 15])\n",
      "pos_emb tensor([[[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]],\n",
      "\n",
      "        [[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]],\n",
      "\n",
      "        [[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]],\n",
      "\n",
      "        [[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]],\n",
      "\n",
      "        [[-0.0817,  0.0722,  0.0871,  ..., -0.0573,  0.0028, -0.0597],\n",
      "         [-0.0308, -0.0089, -0.0369,  ...,  0.0633,  0.0147,  0.0182],\n",
      "         [-0.0056, -0.0616, -0.0096,  ...,  0.0548,  0.0346, -0.0591],\n",
      "         ...,\n",
      "         [ 0.0773,  0.0365,  0.0188,  ...,  0.0246, -0.0193, -0.0821],\n",
      "         [-0.0136, -0.0953, -0.0376,  ...,  0.0088, -0.0454, -0.0075],\n",
      "         [-0.0070, -0.0096, -0.0407,  ..., -0.0578, -0.0386, -0.0001]]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-779619ce3f7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Epoch {epoch+1} of {NUM_EPOCHS}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-144577d2888e>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, dataloader, optim, desc)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/tqdm-4.61.2-py3.6.egg/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/tqdm-4.61.2-py3.6.egg/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/AssistiveVision/loader/dataset_coco.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/AssistiveVision/loader/dataset_coco.py\u001b[0m in \u001b[0;36m__getitem__tensor\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             _, img_tensor = self.__extract_features(\n\u001b[0;32m--> 293\u001b[0;31m                 self.blob.get(fname, self.imageS3.getImageCV(fpath)))\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             img_tensor = self.transformations(\n",
      "\u001b[0;32m~/SageMaker/AssistiveVision/loader/dataset_coco.py\u001b[0m in \u001b[0;36m__extract_features\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             box_features = self.predictor.model.roi_heads._shared_roi_transform(\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             )\n\u001b[1;32m    197\u001b[0m             \u001b[0mfeature_pooled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pooled to 1x1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/py-bottom-up-attention/detectron2/modeling/roi_heads/roi_heads.py\u001b[0m in \u001b[0;36m_shared_roi_transform\u001b[0;34m(self, features, boxes)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_shared_roi_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/py-bottom-up-attention/detectron2/modeling/backbone/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/py-bottom-up-attention/detectron2/layers/wrappers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_min = 100\n",
    "val_loss_min = 100\n",
    "val_cider_max = 0.0\n",
    "patience = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, val_loss = training(model, dataloaders, optim, desc=f'Epoch {epoch+1} of {NUM_EPOCHS}')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores =  evaluate(model, val_eval_loader, bleu_score_fn=corpus_bleu_score_fn, \n",
    "                           tensor_to_word_fn=tensor2word_fn, desc='Eval Score')\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}/{NUM_EPOCHS}')\n",
    "        print('=' * 95)\n",
    "        print(''.join([f'val_bleu{i}: {scores[\"bleu\"][i]:.4f} ' for i in range(1, 5)]))\n",
    "        print(''.join([f'val_coco_bleu{i + 1}{\":\":>5} {scores[\"coco_bleu\"][0][i]:.4f} ' for i in range(0, 4)]))\n",
    "        print(f'val_cider{\":\":>5} {scores[\"cider\"][0]:.4f}')\n",
    "        print(f'val_rouge{\":\":>5} {scores[\"rouge\"][0]:.4f}')\n",
    "        #print(f'val_spcie{\":\":>5} {scores[\"spice\"][0]:.4f}')\n",
    "        #print(f'val_meteor{\":\":>5} {scores[\"meteor\"][0]:.4f}')\n",
    "        print('-' * 95)\n",
    "        \n",
    "        state = dict(\n",
    "            epoch = epoch + 1,\n",
    "            state_dict = model.state_dict(),\n",
    "            train_loss_latest = train_loss,\n",
    "            val_loss_latest = val_loss,\n",
    "            train_loss_min = min(train_loss, train_loss_min),\n",
    "            val_loss_min = min(val_loss, val_loss_min),\n",
    "            val_bleu1 = scores['bleu'][1],\n",
    "            val_bleu4 = scores['bleu'][4],\n",
    "            val_coco_bleu1 = scores['coco_bleu'][0][0],\n",
    "            val_coco_bleu4 = scores['coco_bleu'][0][3],\n",
    "            val_cider = scores['cider'][0],\n",
    "            val_cider_max = max(scores['cider'][0], val_cider_max),\n",
    "            val_rouge = scores['rouge'][0]\n",
    "        )\n",
    "        \n",
    "        if scores['cider'][0] > val_cider_max:\n",
    "            val_cider_max = scores['cider'][0]\n",
    "            fname = f'{MODEL_NAME}_best_v{VERSION}.pth'\n",
    "            # keep the best model\n",
    "            model_bin.save(state, os.path.join(LOCAL_PATH, fname), os.path.join(KEY_PATH, fname))\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "        \n",
    "        if patience == 5:\n",
    "            patience = 0\n",
    "            optim = Adam(model.parameters(), lr=5e-6)\n",
    "        \n",
    "        # save as checkpoint\n",
    "        fname = f'{MODEL_NAME}_ep{epoch + 1}_chkpoint_v{VERSION}.pth'\n",
    "        model_bin.save(state, os.path.join(CHEKCPOINTS_PATH, fname), os.path.join(KEY_PATH, fname))\n",
    "            \n",
    "fname = f'{MODEL_NAME}_ep{NUM_EPOCHS}_latest_v{VERSION}.pth'\n",
    "model_bin.save(state, os.path.join(LOCAL_PATH, fname), os.path.join(KEY_PATH, fname))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
